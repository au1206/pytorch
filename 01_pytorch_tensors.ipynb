{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d5d398-5070-4485-92e4-07295c5df48f",
   "metadata": {},
   "source": [
    "# PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce793814-39be-48a2-8ff8-0e0d9f07a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a08c58c-10ea-4393-812e-67ce2be9eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47367bc-8a2a-4dee-97f1-ac494e194e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b25db0-684c-48d0-b4a1-237e7257fd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01af2e9-55cc-4be4-a5e5-eeba0527c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can traverse\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e5c453-77ed-4b63-9b48-4b98865cb004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can slice\n",
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a81a91a-e813-486c-ac4a-4b92a84a0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutable\n",
    "a[2] = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268b5e7a-1362-4b7e-9475-0a213e71af09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 3.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c98378-1cce-4a51-a4f0-79933bea3de3",
   "metadata": {},
   "source": [
    "**NOTE:** tensors are stored as contiguous memory blocks as float32 (32bits/4bytes) per element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341589d5-7256-434e-8cf8-669c98fb94ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.2000, 2.3000, 3.4000, 4.5000]), torch.Size([4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# createing tensors from list\n",
    "b = torch.tensor([1.2, 2.3, 3.4, 4.5])\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "275738f8-c85c-420a-b8b8-d5c4708d307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2000, 2.3000],\n",
       "         [3.4000, 4.5000]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1.2, 2.3],[3.4, 4.5]])\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4869e90e-f81d-4c09-bada-219fd47a79ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4000, 4.5000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing entry at index 1\n",
    "b[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e03a9995-6985-497d-a709-9034f51e71fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2000, 3.4000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f244cffd-40fd-4459-940a-de25d15f79da",
   "metadata": {},
   "source": [
    "## Giving names to dimensions\n",
    "we can add names to the dimensions using the function refine names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5deac43f-7b27-4a4c-9dcc-b054de5a64d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/AuDev/pytorch/lib/python3.9/site-packages/torch/_tensor.py:780: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return super(Tensor, self).refine_names(names)\n"
     ]
    }
   ],
   "source": [
    "b_named = b.refine_names(...,'rows','columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88748326-ad03-4a11-b5cb-8d176ad2a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) ('rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "print(b_named.shape, b_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e70b8-0362-463b-99f9-47c23431f0f4",
   "metadata": {},
   "source": [
    "Functions that take dimension arguments also accept named dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66b04bc0-cce3-4aba-905b-10a383121a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_col = b_named.sum('columns')\n",
    "summed_row = b_named.sum('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b7a81a6-7301-421a-9de2-3eaf8527eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2000, 2.3000],\n",
      "        [3.4000, 4.5000]], names=('rows', 'columns'))\n",
      "Summed on Columns:  tensor([3.5000, 7.9000], names=('rows',))\n",
      "Summed on Rows:  tensor([4.6000, 6.8000], names=('columns',))\n"
     ]
    }
   ],
   "source": [
    "print(b_named)\n",
    "print(\"Summed on Columns: \",summed_col)\n",
    "print(\"Summed on Rows: \",summed_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b18192-f3d7-4e55-b6da-f71d19968979",
   "metadata": {},
   "source": [
    "**NOTE:** Once named, we cannot combine dimensions with different names i.e. standard broadcasting would not apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee41f5-bde8-46f4-9ff8-c6550b983525",
   "metadata": {},
   "source": [
    "to use functions that do not accept named dimensions we will need to remove the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9950ca0d-6e4c-494e-bd22-fa2772fc4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_named = b_named.rename(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dab7d504-fbf7-43c0-939d-3a7a597546c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2000, 2.3000],\n",
       "        [3.4000, 4.5000]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e71ccfd-bb4d-4289-947c-5b00011ee142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aedbee-df7d-4787-9c09-a8b5d9b0d51e",
   "metadata": {},
   "source": [
    "## DataTypes of tensors\n",
    "- torch.float32 or torch.float: 32-bit floating-point\n",
    "- torch.float64 or torch.double: 64-bit, double-precision floating-point \n",
    "- torch.float16 or torch.half: 16-bit, half-precision floating-point\n",
    "- torch.int8: signed 8-bit integers\n",
    "- torch.uint8: unsigned 8-bit integers\n",
    "- torch.int16 or torch.short: signed 16-bit integers\n",
    "- torch.int32 or torch.int: signed 32-bit integers\n",
    "- torch.int64 or torch.long: signed 64-bit integers\n",
    "- torch.bool: Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e5e909a-6efe-4bec-80e1-7bab594b4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can explicitly mention the dtype for a tensor\n",
    "double_points = torch.ones(10,2,dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "005c86ae-0323-451b-9ae4-afe98a39a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec675f12-8a8a-4b67-9e11-0e7fc063e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way\n",
    "double_points = torch.zeros(10,2).to(torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d80c6f47-35c7-4925-957e-6ae639f1cacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e1e73-2818-480d-afa6-e72e406c61f0",
   "metadata": {},
   "source": [
    "## Storage of Tensors\n",
    "Values in tensors are allocated in contiguous chunks of memory managed by torch.Storage instances. A storage is a one-dimensional array of numerical data: that is, a contiguous block of memory containing numbers of a given type, such as float (32 bits repre- senting a floating-point number) or int64 (64 bits representing an integer). A PyTorch Tensor instance is a view of such a Storage instance that is capable of indexing into that storage using an offset and per-dimension strides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "969dbd1e-400c-486f-ae55-a181e0a368fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2000000476837158\n",
       " 2.299999952316284\n",
       " 3.4000000953674316\n",
       " 4.5\n",
       "[torch.FloatStorage of size 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe413ea4-c9d8-40ba-ba93-db8eb4ed2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4000000953674316"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a146e88-8acf-47d8-9f5b-08c229fa71b1",
   "metadata": {},
   "source": [
    "The indexing of storage is always 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c3f06-5d96-4d67-9b08-4895e80b12a7",
   "metadata": {},
   "source": [
    "while storage the tensors need the following:\n",
    "- Size: The actual shape of the tensord eg: (3,3) for a 3x3 tensor\n",
    "- Offset: The storage offset is the index in the storage corresponding to the first element in the tensor\n",
    "- Stride: The stride is the number of elements in the storage that need to be skipped over to obtain the next element along each dimension\n",
    "\n",
    "<img src=\"assets/pytorch101_3.5.png\" width='750'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7794aaf0-cbd3-4e7b-8a56-86c96dbe0122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8c8f5bd-1469-4429-a02a-f37f0e9bfbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fe9ef-9c15-49a7-8029-9c4d834cd9f2",
   "metadata": {},
   "source": [
    "**Accessing an element i, j in a 2D tensor results in accessing the `storage_offset + stride[0] * i + stride[1] * j` element in the storage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5cf33d-ffd1-4b21-9376-a493d327bafe",
   "metadata": {},
   "source": [
    "A transpose would basically access the same storage with different offset and stride (new tensor object with same memory storage but different size, storage offset, or stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1aac46d6-045f-4ef2-8920-b4409aa2d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# transpose has different object but same storage\n",
    "print(id(b) == id(b.t()))\n",
    "print(id(b.storage()) == id(b.t().storage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "929ed3c5-00f3-4e04-83f0-e4c5391fcd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride(), b.t().stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab27a81-fdb0-4278-bba3-d8574d2b5390",
   "metadata": {},
   "source": [
    "<img src=assets/pytorch101_3.6.png width='750'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fa8483c-83d6-462b-82bf-bacf3adb12f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e294dfd-fca9-4ae4-8782-b7f5535a7192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.t().is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7165e241-7c63-47ac-bfba-833fb1eb8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2000000476837158\n",
       " 2.299999952316284\n",
       " 3.4000000953674316\n",
       " 4.5\n",
       "[torch.FloatStorage of size 4]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d017251c-1960-425e-b77e-2d64caeb6204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2000000476837158\n",
       " 2.299999952316284\n",
       " 3.4000000953674316\n",
       " 4.5\n",
       "[torch.FloatStorage of size 4]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.t().storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b99ec78-3b27-47d3-b9b6-3e7b7d281bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2000, 2.3000],\n",
       "         [3.4000, 4.5000]]),\n",
       " tensor([[1.2000, 3.4000],\n",
       "         [2.3000, 4.5000]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, b.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac549a-0a30-46a6-a944-0acb4e1dd817",
   "metadata": {},
   "source": [
    "**A tensor whose values are laid out in the storage starting from the rightmost dimen- sion onward (that is, moving along rows for a 2D tensor) is defined as contiguous.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14425c6a-b007-42aa-89fc-19338924f9be",
   "metadata": {},
   "source": [
    "Some operations are only valid for contiguous tensors. we can obtain a contiguous tensor from a non_contiguous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a16dbe45-5bf6-4051-8b34-ee820c087903",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t = b.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b602736-5173-4b28-991c-1adfd5eeda45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76487bec-d0fd-4971-a16b-1bfab732e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t = b_t.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53cfe9cb-5b5e-475f-8af9-581229591177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c8f9762-0f61-4d09-830e-24305cb1f862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2000000476837158\n",
       " 3.4000000953674316\n",
       " 2.299999952316284\n",
       " 4.5\n",
       "[torch.FloatStorage of size 4]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d59eb4d3-11a0-44fa-ac74-d70d6fa39624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(b_t.storage()) == id(b.t().storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12c95d20-d669-4c58-a0c0-db897b138fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (2, 1))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.stride(), b.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59aa69-bd54-442d-93a7-e4a9d7f1c3bb",
   "metadata": {},
   "source": [
    "## Moving tensors to GPU\n",
    "along with names, dtype tensors have another attribute called `device`. \n",
    "\n",
    "`device='cuda'` indicates that its placed on a. GPU\n",
    "\n",
    "- in case there are ,ultiple GPUs we can specify the device as `points_gpu = points.to(device='cuda:0')`\n",
    "- we can perform a tensor operation on GOU as `points_gpu = 2 * points.to(device='cuda')`\n",
    "    - The points tensor is copied to the GPU.\n",
    "    - A new tensor is allocated on the GPU and used to store the result of the multiplication.\n",
    "    - A handle to that GPU tensor is returned.\n",
    "    \n",
    "-  we can move a tensor to cpu as well `points_cpu = points_gpu.to(device='cpu')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562489f-a382-49e0-8703-adbb601d9303",
   "metadata": {},
   "source": [
    "## NumPy and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12da46ce-c002-4322-8be4-5f7f7f714d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = torch.ones(3,4)\n",
    "tens_np = tens.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dd5001b6-079f-49c9-b71b-02d117602ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=float32),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_np, tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc429f6-236f-4018-9b1a-34bdc80a7a45",
   "metadata": {},
   "source": [
    "the numpy array shares the same storage, making this an efficient operation, but changing the numpy array will cause the tensor to change as well.\n",
    "\n",
    "If the tensor is on GPU a CPU copy is first created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3597b238-1a58-4e97-89da-f7a5123c6831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "tens_2 = torch.from_numpy(tens_np)\n",
    "tens_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f279e-5b36-4ea6-b9fb-8cb56fe2c0b2",
   "metadata": {},
   "source": [
    "**NOTE:** While the default numeric type in PyTorch is 32-bit floating-point, for NumPy it is 64-bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d30f1d-8a0d-4979-a6db-a3d8a72f0a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
